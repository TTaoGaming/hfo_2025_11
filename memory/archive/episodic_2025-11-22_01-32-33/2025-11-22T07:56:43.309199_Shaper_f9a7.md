---
id: f9a7
role: Shaper
round: 2
timestamp: 2025-11-22T07:56:43.309199
---

As a Shaper, I will identify the core components and architecture of the SWARM Loop based on objective knowledge of OpenAI's Swarm framework, which features a central execution loop for multi-agent orchestration. I have no direct access to files or prior context mentioning 'SWARM Loop' specifically, so this draws from publicly documented facts about OpenAI Swarm (released experimentally in 2024). To gather more evidence, I recommend using available tools like 'search_web' for 'SWARM Loop architecture' or 'read_file' if documentation exists locally. Here's the parsed analysis:

### Core Components:
1. **Agents**: Core entities defined by:
   - `name`: Unique identifier.
   - `instructions`: System prompt guiding behavior.
   - `functions`: List of tools (Python callables) the agent can use.
   - `handoffs`: Dictionary mapping handoff triggers to other agent names.

2. **Swarm Class**: The orchestrator managing the loop.
   - Initialized with a list of agents.
   - Default agent for starting conversations.

3. **Messages**: List of dicts with 'role' ('user' or 'assistant') and 'content' (string or tool call results).

4. **Tools/Functions**: Python functions agents invoke, returning results appended to messages.

5. **Handoffs**: Mechanism for agents to delegate to others via special function calls.

### Architecture of the SWARM Loop:
The SWARM Loop is an event-driven execution cycle in the `swarm.Swarm.run()` method:

1. **Input**: Conversation history (list of messages) and optional agent override.
2. **Select Active Agent**: Use handoff from last assistant message or fallback to default.
3. **Generate Response**:
   - Format messages for LLM (e.g., ChatOpenAI).
   - Call LLM with agent's instructions.
4. **Execute Response**:
   - If tool call: Execute function, append tool result message.
   - If handoff: Transfer to specified agent (loop continues).
   - Else: Append assistant message.
5. **Loop**: Recurse until no handoff/tool call or max iterations.
6. **Output**: Updated messages list.

This forms a **reactive, handoff-based loop** without complex state management, emphasizing simplicity over RLHF-trained routers. Evidence: OpenAI Swarm GitHub repo (github.com/openai/swarm), docs describe the `run` method as iteratively processing until resolution.

Pseudocode:
```
def run(messages, agent=None):
    while True:
        agent = select_agent(messages, agent)
        response = llm.chat(messages, agent.instructions)
        if handoff in response:
            agent = agent.handoffs[handoff]
        elif tool_call in response:
            result = execute_tool(tool_call)
            messages.append(tool_result)
        else:
            messages.append(response)
            break
    return messages
```

Honest note: If 'SWARM Loop' refers to a different system (e.g., robotics, custom framework), please provide context or use 'search_web("SWARM Loop architecture")' for verification.
